---
title: 性能优化和缓存策略
epic: tms-nlops-demo
task_id: 039
type: task
status: todo
priority: high
tags: ["performance", "optimization", "cache", "scaling", "monitoring"]
assignee: ""
created: 2025-09-20T04:20:45Z
updated: 2025-09-20T04:20:45Z
parallel: false
depends_on: ["016", "017", "018", "019", "020", "021", "022", "023", "024", "025", "030", "031", "032", "033", "034", "035", "036", "037", "038"]
effort: 4
description: 实施性能优化策略和缓存机制，提升系统响应速度和用户体验
---

## 任务描述

对TMS NL-Ops演示系统进行全面的性能优化，实施多层缓存策略、数据库优化、前端性能优化和监控系统，确保系统在高并发和大数据量下的稳定运行。

## 详细需求

### 1. 前端性能优化
- **代码分割**: 实现按需加载和懒加载
- **缓存策略**: 浏览器缓存和CDN缓存
- **图片优化**: 图片压缩和懒加载
- **渲染优化**: 减少重渲染和虚拟滚动
- **包大小优化**: 减少JavaScript包大小

### 2. 后端性能优化
- **数据库优化**: 查询优化和索引设计
- **API优化**: 接口响应时间和并发处理
- **缓存策略**: Redis缓存和本地缓存
- **异步处理**: 非阻塞IO和队列处理
- **连接池**: 数据库连接池管理

### 3. AI响应优化
- **模型缓存**: LLM响应缓存
- **流式处理**: 优化流式响应
- **工具调用**: 工具调用缓存
- **会话管理**: 高效的会话状态管理
- **并行处理**: 多线程并发处理

### 4. 监控和告警
- **性能监控**: 实时性能指标监控
- **错误监控**: 错误率和异常监控
- **资源监控**: CPU、内存、磁盘监控
- **用户监控**: 用户行为和体验监控
- **告警机制**: 自动告警和通知

## 技术实现

### 前端性能优化
```typescript
// next.config.js
/** @type {import('next').NextConfig} */
const nextConfig = {
  reactStrictMode: true,
  swcMinify: true,

  // 启用压缩
  compress: true,

  // 图片优化配置
  images: {
    domains: ['localhost'],
    formats: ['image/webp', 'image/avif'],
    deviceSizes: [640, 750, 828, 1080, 1200, 1920, 2048, 3840],
    imageSizes: [16, 32, 48, 64, 96, 128, 256, 384],
  },

  // 代码分割配置
  webpack: (config, { dev, isServer }) => {
    if (!dev && !isServer) {
      Object.assign(config.optimization.splitChunks, {
        chunks: 'all',
        minSize: 20000,
        maxSize: 244000,
        minChunks: 1,
        maxAsyncRequests: 30,
        maxInitialRequests: 30,
        cacheGroups: {
          default: false,
          vendor: {
            test: /[\\/]node_modules[\\/]/,
            name: 'vendor',
            chunks: 'all',
            priority: 10,
          },
          common: {
            name: 'common',
            minChunks: 2,
            chunks: 'all',
            priority: 5,
          },
        },
      });
    }
    return config;
  },

  // 启用实验性功能
  experimental: {
    optimizeCss: true,
    optimizePackageImports: ['lucide-react', '@radix-ui/react-dialog'],
  },
};

module.exports = nextConfig;

// components/optimized/OptimizedImage.tsx
'use client';
import Image from 'next/image';
import { useState } from 'react';

interface OptimizedImageProps {
  src: string;
  alt: string;
  width: number;
  height: number;
  className?: string;
  priority?: boolean;
}

export function OptimizedImage({
  src,
  alt,
  width,
  height,
  className,
  priority = false
}: OptimizedImageProps) {
  const [isLoading, setIsLoading] = useState(true);
  const [error, setError] = useState(false);

  return (
    <div className={`relative overflow-hidden ${className}`}>
      {isLoading && (
        <div className="absolute inset-0 bg-gray-200 animate-pulse" />
      )}

      <Image
        src={src}
        alt={alt}
        width={width}
        height={height}
        className={`
          duration-700 ease-in-out
          ${isLoading ? 'scale-110 blur-2xl grayscale' : 'scale-100 blur-0 grayscale-0'}
        `}
        onLoadingComplete={() => setIsLoading(false)}
        onError={() => {
          setIsLoading(false);
          setError(true);
        }}
        priority={priority}
        placeholder="blur"
        blurDataURL="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAABAAEDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAv/xAAUEAEAAAAAAAAAAAAAAAAAAAAA/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAX/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwCdABmX/9k="
      />

      {error && (
        <div className="absolute inset-0 flex items-center justify-center bg-gray-100">
          <span className="text-gray-400 text-sm">图片加载失败</span>
        </div>
      )}
    </div>
  );
}
```

### 数据库优化
```typescript
// lib/db-optimized.ts
import { PrismaClient } from '@prisma/client';
import { performance } from 'perf_hooks';

const prismaClientSingleton = () => {
  return new PrismaClient({
    log: ['query', 'info', 'warn', 'error'],
    errorFormat: 'pretty',
    datasources: {
      db: {
        url: process.env.DATABASE_URL + '&connection_limit=10&pool_timeout=20'
      }
    }
  });
};

declare global {
  var prisma: undefined | ReturnType<typeof prismaClientSingleton>;
}

const prisma = globalThis.prisma ?? prismaClientSingleton();

if (process.env.NODE_ENV !== 'production') globalThis.prisma = prisma;

// 查询性能监控
export async function measureQuery<T>(name: string, query: () => Promise<T>): Promise<T> {
  const startTime = performance.now();
  try {
    const result = await query();
    const endTime = performance.now();
    const duration = endTime - startTime;

    // 记录慢查询
    if (duration > 1000) {
      console.warn(`Slow query detected: ${name} took ${duration}ms`);
    }

    // 发送到监控系统
    await recordQueryMetric(name, duration);

    return result;
  } catch (error) {
    const endTime = performance.now();
    const duration = endTime - startTime;
    await recordQueryError(name, duration, error);
    throw error;
  }
}

// 优化的订单查询
export async function getOrdersOptimized(params: {
  customerId?: string;
  status?: string;
  dateRange?: { start: Date; end: Date };
  page?: number;
  limit?: number;
}) {
  return measureQuery('getOrdersOptimized', async () => {
    const { customerId, status, dateRange, page = 1, limit = 20 } = params;
    const skip = (page - 1) * limit;

    const where = {
      ...(customerId && { customerId }),
      ...(status && { status }),
      ...(dateRange && {
        createdAt: {
          gte: dateRange.start,
          lte: dateRange.end
        }
      })
    };

    const [orders, total] = await Promise.all([
      prisma.order.findMany({
        where,
        include: {
          customer: {
            select: {
              id: true,
              name: true,
              phone: true
            }
          },
          dispatch: {
            select: {
              id: true,
              dispatchNo: true,
              status: true,
              vehicle: {
                select: {
                  id: true,
                  plateNumber: true,
                  driverName: true
                }
              }
            }
          },
          _count: {
            select: {
              tracking: true
            }
          }
        },
        orderBy: { createdAt: 'desc' },
        skip,
        take: limit
      }),
      prisma.order.count({ where })
    ]);

    return {
      orders,
      pagination: {
        page,
        limit,
        total,
        totalPages: Math.ceil(total / limit)
      }
    };
  });
}

// 批量操作优化
export async function batchCreateOrders(ordersData: any[]) {
  return measureQuery('batchCreateOrders', async () => {
    return await prisma.$transaction(async (tx) => {
      const results = await Promise.all(
        ordersData.map(async (orderData) => {
          // 查找或创建客户
          const customer = await tx.customer.upsert({
            where: { name: orderData.customerName },
            update: {},
            create: {
              name: orderData.customerName,
              phone: orderData.customerPhone,
              email: orderData.customerEmail
            }
          });

          // 创建订单
          return tx.order.create({
            data: {
              orderId: generateOrderId(),
              customerId: customer.id,
              origin: orderData.origin,
              destination: orderData.destination,
              weight: orderData.weight,
              volume: orderData.volume,
              goodsType: orderData.goodsType,
              specialReq: orderData.specialReq,
              scheduledAt: orderData.scheduledAt
                ? new Date(orderData.scheduledAt)
                : undefined
            }
          });
        })
      );

      return results;
    });
  });
}
```

### 缓存策略
```typescript
// lib/cache/redis-cache.ts
import Redis from 'ioredis';
import { createHash } from 'crypto';

const redis = new Redis(process.env.REDIS_URL || 'redis://localhost:6379', {
  retryDelayOnFailover: 100,
  maxRetriesPerRequest: 3,
  lazyConnect: true,
  connectTimeout: 10000,
  commandTimeout: 5000
});

redis.on('error', (err) => {
  console.error('Redis error:', err);
});

export interface CacheOptions {
  ttl?: number; // 过期时间（秒）
  key?: string; // 自定义缓存键
  namespace?: string; // 命名空间
  compress?: boolean; // 是否压缩
}

export class CacheManager {
  private static instance: CacheManager;

  static getInstance(): CacheManager {
    if (!CacheManager.instance) {
      CacheManager.instance = new CacheManager();
    }
    return CacheManager.instance;
  }

  private generateKey(
    prefix: string,
    args: any[],
    options: CacheOptions = {}
  ): string {
    const { namespace = 'tms' } = options;
    const argsString = JSON.stringify(args);
    const hash = createHash('md5').update(argsString).digest('hex');
    return `${namespace}:${prefix}:${hash}`;
  }

  async get<T>(
    key: string,
    fetcher: () => Promise<T>,
    options: CacheOptions = {}
  ): Promise<T> {
    const cacheKey = this.generateKey(key, [], options);
    const { ttl = 300 } = options; // 默认5分钟

    try {
      // 尝试从缓存获取
      const cached = await redis.get(cacheKey);
      if (cached) {
        return JSON.parse(cached);
      }

      // 缓存未命中，获取数据
      const data = await fetcher();

      // 设置缓存
      await redis.setex(cacheKey, ttl, JSON.stringify(data));

      return data;
    } catch (error) {
      console.error('Cache error:', error);
      // 缓存失败时直接返回数据
      return fetcher();
    }
  }

  async set(key: string, value: any, options: CacheOptions = {}): Promise<void> {
    const cacheKey = this.generateKey(key, [], options);
    const { ttl = 300 } = options;

    try {
      await redis.setex(cacheKey, ttl, JSON.stringify(value));
    } catch (error) {
      console.error('Cache set error:', error);
    }
  }

  async invalidate(pattern: string): Promise<void> {
    try {
      const keys = await redis.keys(`tms:${pattern}:*`);
      if (keys.length > 0) {
        await redis.del(...keys);
      }
    } catch (error) {
      console.error('Cache invalidate error:', error);
    }
  }

  async clear(): Promise<void> {
    try {
      await redis.flushdb();
    } catch (error) {
      console.error('Cache clear error:', error);
    }
  }

  // 查询结果缓存
  async cachedQuery<T>(
    queryName: string,
    params: any,
    queryFn: () => Promise<T>,
    options: CacheOptions = {}
  ): Promise<T> {
    const cacheKey = `query:${queryName}:${JSON.stringify(params)}`;
    return this.get(cacheKey, queryFn, options);
  }

  // AI响应缓存
  async cachedAIResponse(
    prompt: string,
    model: string,
    responseFn: () => Promise<any>,
    options: CacheOptions = {}
  ): Promise<any> {
    const cacheKey = `ai:${model}:${createHash('md5').update(prompt).digest('hex')}`;
    return this.get(cacheKey, responseFn, { ...options, ttl: 3600 }); // AI缓存1小时
  }

  // 会话状态缓存
  async getSession(sessionId: string): Promise<any> {
    return this.get(`session:${sessionId}`, async () => {
      throw new Error('Session not found');
    }, { ttl: 3600 });
  }

  async setSession(sessionId: string, data: any): Promise<void> {
    await this.set(`session:${sessionId}`, data, { ttl: 3600 });
  }
}

export const cacheManager = CacheManager.getInstance();

// API响应缓存中间件
export function withCache(
  keyPrefix: string,
  options: CacheOptions = {}
) {
  return (handler: any) => {
    return async (req: any, res: any) => {
      const cacheKey = `${keyPrefix}:${JSON.stringify(req.query)}`;

      try {
        const cached = await cacheManager.get(cacheKey, async () => {
          const originalJson = res.json;
          let response: any;

          res.json = (data: any) => {
            response = data;
            return originalJson.call(res, data);
          };

          await handler(req, res);
          return response;
        }, options);

        if (cached) {
          return res.json(cached);
        }
      } catch (error) {
        console.error('Cache middleware error:', error);
        await handler(req, res);
      }
    };
  };
}
```

### AI性能优化
```typescript
// lib/ai/optimized.ts
import { openai } from '@ai-sdk/openai';
import { streamText, CoreMessage } from 'ai';
import { cacheManager } from '../cache/redis-cache';

interface AIRequestOptions {
  model?: string;
  temperature?: number;
  maxTokens?: number;
  system?: string;
  tools?: any;
  maxSteps?: number;
}

export class OptimizedAIService {
  private static instance: OptimizedAIService;

  static getInstance(): OptimizedAIService {
    if (!OptimizedAIService.instance) {
      OptimizedAIService.instance = new OptimizedAIService();
    }
    return OptimizedAIService.instance;
  }

  async generateResponse(
    messages: CoreMessage[],
    options: AIRequestOptions = {}
  ) {
    const {
      model = 'gpt-4-turbo-preview',
      temperature = 0.7,
      maxTokens = 2000,
      system = '你是一个智能运输管理助手',
      tools,
      maxSteps = 5
    } = options;

    // 生成缓存键
    const cacheKey = `ai:${model}:${JSON.stringify(messages.slice(-3))}:${JSON.stringify(options)}`;

    return cacheManager.get(cacheKey, async () => {
      const startTime = Date.now();

      try {
        const result = await streamText({
          model: openai(model),
          messages,
          system,
          tools,
          maxSteps,
          temperature,
          maxTokens,
          abortSignal: AbortSignal.timeout(30000), // 30秒超时
          async onFinish({ responseMessages, usage }) {
            // 记录性能指标
            await recordAIMetrics({
              model,
              duration: Date.now() - startTime,
              inputTokens: usage?.promptTokens || 0,
              outputTokens: usage?.completionTokens || 0,
              totalTokens: usage?.totalTokens || 0,
              toolCalls: responseMessages.flatMap(m => m.tool_calls || []).length
            });
          }
        });

        return result;
      } catch (error) {
        console.error('AI service error:', error);
        throw error;
      }
    }, { ttl: 300 }); // 5分钟缓存
  }

  // 并行处理多个AI请求
  async parallelProcess(
    requests: Array<{
      messages: CoreMessage[];
      options?: AIRequestOptions;
    }>
  ) {
    return Promise.allSettled(
      requests.map(req => this.generateResponse(req.messages, req.options))
    );
  }

  // 流式响应优化
  async *optimizedStreamResponse(
    messages: CoreMessage[],
    options: AIRequestOptions = {}
  ) {
    const result = await this.generateResponse(messages, options);

    for await (const chunk of result.textStream) {
      yield {
        type: 'text',
        content: chunk,
        timestamp: Date.now()
      };
    }
  }
}

export const optimizedAI = OptimizedAIService.getInstance();

// 性能监控
async function recordAIMetrics(metrics: any) {
  try {
    // 发送到监控系统
    await fetch(`${process.env.MONITORING_URL}/metrics/ai`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(metrics)
    });
  } catch (error) {
    console.error('Failed to record AI metrics:', error);
  }
}
```

### 监控和告警
```typescript
// lib/monitoring/performance.ts
import { performance } from 'perf_hooks';

interface PerformanceMetrics {
  endpoint: string;
  method: string;
  duration: number;
  statusCode: number;
  memoryUsage: NodeJS.MemoryUsage;
  timestamp: number;
}

class PerformanceMonitor {
  private static instance: PerformanceMonitor;
  private metrics: PerformanceMetrics[] = [];
  private readonly MAX_METRICS = 1000;

  static getInstance(): PerformanceMonitor {
    if (!PerformanceMonitor.instance) {
      PerformanceMonitor.instance = new PerformanceMonitor();
    }
    return PerformanceMonitor.instance;
  }

  recordRequest(metrics: Omit<PerformanceMetrics, 'timestamp' | 'memoryUsage'>) {
    const memoryUsage = process.memoryUsage();
    const fullMetrics: PerformanceMetrics = {
      ...metrics,
      memoryUsage,
      timestamp: Date.now()
    };

    this.metrics.push(fullMetrics);

    // 保持数组大小
    if (this.metrics.length > this.MAX_METRICS) {
      this.metrics = this.metrics.slice(-this.MAX_METRICS);
    }

    // 检查性能告警
    this.checkPerformanceAlerts(fullMetrics);

    // 异步发送到监控系统
    this.sendToMonitoring(fullMetrics);
  }

  private checkPerformanceAlerts(metrics: PerformanceMetrics) {
    // 响应时间告警
    if (metrics.duration > 5000) {
      this.sendAlert('high_response_time', {
        endpoint: metrics.endpoint,
        duration: metrics.duration,
        threshold: 5000
      });
    }

    // 内存使用告警
    if (metrics.memoryUsage.heapUsed > 500 * 1024 * 1024) { // 500MB
      this.sendAlert('high_memory_usage', {
        heapUsed: metrics.memoryUsage.heapUsed,
        threshold: 500 * 1024 * 1024
      });
    }

    // 错误率告警
    if (metrics.statusCode >= 400) {
      this.sendAlert('http_error', {
        endpoint: metrics.endpoint,
        statusCode: metrics.statusCode
      });
    }
  }

  private async sendToMonitoring(metrics: PerformanceMetrics) {
    try {
      await fetch(`${process.env.MONITORING_URL}/api/metrics`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(metrics)
      });
    } catch (error) {
      console.error('Failed to send metrics:', error);
    }
  }

  private async sendAlert(type: string, data: any) {
    try {
      await fetch(`${process.env.ALERT_URL}/api/alerts`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          type,
          severity: 'warning',
          data,
          timestamp: Date.now()
        })
      });
    } catch (error) {
      console.error('Failed to send alert:', error);
    }
  }

  getMetrics(): PerformanceMetrics[] {
    return [...this.metrics];
  }

  getAverageResponseTime(endpoint?: string): number {
    const relevantMetrics = endpoint
      ? this.metrics.filter(m => m.endpoint === endpoint)
      : this.metrics;

    if (relevantMetrics.length === 0) return 0;

    const total = relevantMetrics.reduce((sum, m) => sum + m.duration, 0);
    return total / relevantMetrics.length;
  }

  getErrorRate(endpoint?: string): number {
    const relevantMetrics = endpoint
      ? this.metrics.filter(m => m.endpoint === endpoint)
      : this.metrics;

    if (relevantMetrics.length === 0) return 0;

    const errors = relevantMetrics.filter(m => m.statusCode >= 400).length;
    return (errors / relevantMetrics.length) * 100;
  }
}

export const performanceMonitor = PerformanceMonitor.getInstance();

// 性能中间件
export function performanceMiddleware() {
  return (req: any, res: any, next: any) => {
    const startTime = performance.now();

    // 监控响应结束
    const originalEnd = res.end;
    res.end = function(chunk?: any) {
      const endTime = performance.now();
      const duration = endTime - startTime;

      performanceMonitor.recordRequest({
        endpoint: req.path,
        method: req.method,
        duration,
        statusCode: res.statusCode
      });

      originalEnd.call(this, chunk);
    };

    next();
  };
}
```

## 交付成果

1. **前端优化配置**: Next.js优化配置和组件
2. **数据库优化**: 查询优化和索引设计
3. **缓存系统**: Redis缓存实现
4. **AI服务优化**: 性能优化的AI服务
5. **监控系统**: 性能监控和告警
6. **优化工具**: 性能分析工具
7. **文档**: 性能优化指南

## 验收标准

- [ ] 页面加载时间 < 2秒
- [ ] API响应时间 < 500ms
- [ ] AI响应时间 < 3秒
- [ ] 缓存命中率 > 70%
- [ ] 数据库查询时间 < 100ms
- [ ] 内存使用率 < 80%
- [ ] 错误率 < 1%
- [ ] 并发用户支持 > 100
- [ ] 监控系统正常运行
- [ ] 告警机制有效
- [ ] 性能指标可追踪
- [ ] 代码符合优化规范

## 相关文件

- `/next.config.js` - Next.js优化配置
- `/lib/cache/redis-cache.ts` - Redis缓存管理
- `/lib/db-optimized.ts` - 数据库优化
- `/lib/ai/optimized.ts` - AI服务优化
- `/lib/monitoring/performance.ts` - 性能监控
- `/components/optimized/` - 优化组件
- `/middleware/performance.ts` - 性能中间件
- `/scripts/performance-test.js` - 性能测试脚本

## 注意事项

1. 渐进优化：不要一次性优化所有内容
2. 基准测试：优化前做好基准测试
3. 监控验证：优化效果要通过监控验证
4. 平衡取舍：在性能和功能之间找到平衡
5. 文档记录：记录优化过程和效果
6. 定期评估：定期评估优化效果
7. 回滚准备：优化失败时要能快速回滚
8. 团队协作：与团队共享优化经验